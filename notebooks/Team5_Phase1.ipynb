{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RbelOPK4TFB"
      },
      "source": [
        "# business and data understanding\n",
        "------------\n",
        "\n",
        "The initial phase is concerned with tasks to define the business objectives and translate it to ML objectives, to collect and verify the data quality and to finaly assess the project feasibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZZ0T5RTaQon"
      },
      "source": [
        "![](https://i.imgur.com/55J7fBc.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "516PRaCCaQoo"
      },
      "source": [
        "## Terminology\n",
        "\n",
        "### tasks\n",
        "\n",
        "Compile a glossary of terminology relevant to the project. This may include two components:\n",
        "(1) A glossary of relevant business terminology, which forms part of the business understanding available to the project. Constructing this glossary is a useful \"knowledge elicitation\" and education exercise.\n",
        "(2) A glossary of machine learning terminology, illustrated with examples relevant to the business problem in question.\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. Business terminology\n",
        "A table or paragraph contains all the business related terms to be used in the project.\n",
        "\n",
        "> ##### Example:\n",
        "> - Key Performance Indicators (KPIs): Quantifiable metrics used to measure the performance of a business or organization. The company's KPIs include revenue growth, customer satisfaction, and employee retention.\n",
        "> - Market Segmentation: Dividing a market into distinct groups based on demographics, needs, or preferences. Example: \"The company segmented its target market into young professionals, families, and retirees to tailor marketing strategies.\"\n",
        "> Return on Investment (ROI): The return or profit generated by an investment compared to its cost. Example: \"The company calculated a 20% ROI on its new marketing campaign, indicating a successful investment.\"\n",
        "\n",
        "#### 2. ML terminology\n",
        "A table or paragraph contains all the ML related terms to be used in the project.\n",
        "\n",
        "\n",
        "> ##### Example:\n",
        "> Underfitting: When a machine learning model is too simple and fails to capture the underlying patterns in the data. Example: \"The company's initial model was underfitting the data, so they added more features and layers to improve accuracy.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminology\n",
        "\n",
        "#### 1. Business terminology\n",
        "\n",
        "> - **Airbnb** : An online marketplace that connects people who want to rent out their homes with those looking for accommodations.\n",
        "> - **Listing**: An individual rental property available on Airbnb.\n",
        ">- **Occupancy Rate**: The percentage of available rental units that are occupied at a given time.\n",
        ">- **Revenue Optimization**: The process of adjusting prices to maximize income from rental properties.\n",
        ">- **Short-term Rental Market**: A segment of the rental market that offers accommodations for a short duration, typically less than a month.\n",
        ">-**Dynamic Pricing**: A pricing strategy where prices are adjusted based on real-time supply and demand conditions.\n",
        ">-**Booking Window**: The time frame between when a guest books a rental and the start of their stay.\n",
        ">-**Cancellation Policy**: The rules set by the host regarding the conditions under which a guest can cancel a reservation and receive a refund.\n",
        ">-**Review Rating**: A score given by guests based on their stay, reflecting the quality of the property and the host's service.\n",
        ">-**Cleaning Fee**: An additional charge imposed by the host for cleaning the property after a guest's stay.\n",
        ">-**Amenities**: Features provided by the rental property, such as Wi-Fi, parking, or a swimming pool.\n",
        ">-**Property Type**: The classification of rental properties, such as apartment, house, or villa.\n",
        ">-**Location**: The geographical area where the rental property is situated, impacting its attractiveness and price.\n",
        ">-**Seasonality**: Fluctuations in demand and prices due to seasonal factors, >-**Competitive Analysis**: The process of evaluating similar listings in the area to set competitive prices.\n",
        ">-**Market Trends**: Changes and patterns in the short-term rental market that influence demand and pricing.\n",
        ">-**Minimum Stay Requirement**: The shortest duration a guest can book a property, as set by the host.\n",
        ">-**Check-in/Check-out Policy**: The rules and timings related to when guests can arrive and depart from the rental property.\n",
        "\n",
        "\n",
        "#### 2. ML terminology\n",
        "\n",
        ">- **Regression**: A supervised learning technique used to predict continuous values, such as the price of an Airbnb listing based on its features.\n",
        ">- **Classification**: A supervised learning technique used to predict categorical outcomes, such as whether a listing will be booked or not.\n",
        ">-**Feature Engineering**: The process of selecting, modifying, and creating new variables (features) that enhance the performance of ML models.\n",
        ">-**Training Data**: The subset of data used to train ML models, containing input-output pairs.\n",
        ">-**Validation Data**: A subset of data used to tune model parameters and prevent overfitting by evaluating model performance.\n",
        ">-**Test Data**: A subset of data used to assess the final performance of the model after training and validation.\n",
        ">-**Overfitting**: A modeling error that occurs when the ML model captures noise in the training data, performing well on training data but poorly on new, unseen data.\n",
        ">-**Underfitting**: A modeling error that occurs when the ML model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and test data.\n",
        ">-**Cross-Validation**: A technique for assessing how the results of a statistical analysis will generalize to an independent dataset, typically by partitioning the data into subsets and training/testing the model multiple times.\n",
        ">-**Hyperparameters**: Settings that define the model architecture and learning process, such as learning rate or number of trees in a random forest, which need to be specified before training.\n",
        ">-**Model Evaluation Metrics**: Measures used to evaluate the performance of ML models, such as Mean Absolute Error (MAE) for regression or Accuracy for classification.\n",
        ">-**Feature Importance**: A technique to determine the significance of individual features in predicting the target variable.\n",
        ">-**Normalization**: A preprocessing step that scales features to a standard range, often 0 to 1, to ensure equal contribution to the model.\n",
        ">-**ROC Curve**: A graphical plot that illustrates the diagnostic ability of a binary classifier system, plotting the true positive rate against the false positive rate.\n",
        ">-**F1 Score**: A measure of a test's accuracy that considers both precision and recall, providing a single metric that balances both aspects.\n",
        ">-**Data Preprocessing**: The process of cleaning and preparing raw data for ML, involving steps like handling missing values, encoding categorical variables, and normalizing data.\n",
        ">-**Exploratory Data Analysis (EDA**): An approach to analyzing data sets to summarize their main characteristics, often using visual methods, before applying more formal modeling techniques."
      ],
      "metadata": {
        "id": "GATbYc9-xd1u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfrdzmhe0Zfr"
      },
      "source": [
        "## Scope of the project\n",
        "----------\n",
        "\n",
        "### tasks\n",
        "- Explore the background of the business.\n",
        "- Define business problem\n",
        "- Define business objectives\n",
        "- Translate business objectives into ML objectives\n",
        "\n",
        "The objective here is to thoroughly understand, from a business perspective, what the client really wants to accomplish. Often the client has many competing objectives and constraints that must be properly balanced. The goal is to uncover important factors, at the beginning, that can influence the outcome of the project. A possible consequence of neglecting this step is to expend a great deal of effort producing the right answers to the wrong questions.\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. background\n",
        "\n",
        "A short paragraph to record the information that is known about the organization's business situation at the beginning of the project.\n",
        "\n",
        "> ##### Example:\n",
        "> Shopzilla is an an e-commerce platform. They have branches in different cities. They have a Mobile app which allows clients to buy products. They profile the purchase history of the users and use this data for building AI models.\n",
        "\n",
        "#### 2. business problem\n",
        "A short paragraph to describe the business problem.\n",
        "\n",
        "> ##### Example:\n",
        "> The business problem is that the business stakeholders wants to follow a customer centric sales methodology. They want to predict customer satisfaction in their services such that they can adapt their strategies accordingly. The provided dataset is labelled and captures customer satisfaction scores for a one-month period. It includes various features such as category and sub-category of interaction, customer remarks, survey response date, category, item price, agent details (name, supervisor, manager), and CSAT score etc.\n",
        "> The company has been experiencing high customer churn rates, resulting in significant revenue losses.\n",
        "\n",
        "#### 3. business objectives\n",
        "\n",
        "A list of business objectives which describes the customer's primary objective, from a business perspective. In addition to the primary business objective, there are typically other related business questions that the customer would like to address. For example, the primary business goal might be to keep current customers by predicting when they are prone to move to a competitor. Examples of related business questions are \"How does the primary channel (e.g., ATM, visit branch, internet) a bank customer uses affect whether they stay or go?\" or \"Will lower ATM fees significantly reduce the number of high-value customers who leave?\"\n",
        "\n",
        "> ##### Examples:\n",
        "> - Will lower ATM fees significantly reduce the number of high-value customers who leave?\n",
        "> - Does the channel used affect whether customers stay or go?\n",
        "\n",
        "#### 4. ML objectives\n",
        "\n",
        "A list of business objectives which describes the intended outputs of the project that enables the achievement of the business objectives.\n",
        "\n",
        "> ##### Examples:\n",
        "> Predict how many widgets a customer will buy, given their purchases over the past three years, demographic information (age, salary, city, etc.), and the price of the item."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Background**\n",
        "\n",
        "  Airbnb is a leading online marketplace that connects people looking to rent out their properties with those seeking short-term accommodations. Currently, Airbnb faces challenges in optimizing pricing strategies for different listings, considering varying demand across locations and seasons. The organization has collected substantial data on past bookings, pricing, customer reviews, and property features, which can be leveraged to enhance pricing strategies and improve occupancy rates.\n",
        "\n",
        "**2. Business Problem**\n",
        "\n",
        "  The primary business problem is to optimize the pricing of Airbnb listings to maximize revenue while maintaining high occupancy rates. This involves dynamically adjusting prices based on various factors, such as location, seasonality, property features, and market trends, to attract more bookings and enhance overall profitability.\n",
        "\n",
        "**3. Business Objectives**\n",
        "\n",
        "  The main objective of the project is to develop a dynamic pricing model that optimizes rental prices for Airbnb listings to maximize revenue and maintain high occupancy rates.\n",
        "\n",
        "**4. ML Objectives**\n",
        "\n",
        "  The goal is to develop a predictive model that predicts the optimal pricing for Airbnb listings based on historical booking data, property characteristics, location details, and market trends."
      ],
      "metadata": {
        "id": "IP4u6p7WxgAu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRCq_z_raQop"
      },
      "source": [
        "## Success Criteria\n",
        "-------------\n",
        "\n",
        "### tasks\n",
        "- Describe the success criteria of the ML project on three different levels: the business success criteria, the ML success criteria and the economic success criteria.\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. Business success criteria\n",
        "A list of criteria  from a business point of view. For example, if an ML application is planned for a quality check in production and is supposed to outperform the current manual failure rate of 3%, the business success criterion could be derived as e.g. \"failure rate less than 3%\"\n",
        "\n",
        "> ##### Example:\n",
        "> - Increase customer satisfaction ratings by 8% within the next quarter.\n",
        "> - Reduce operational costs by 12% within the next year.\n",
        "\n",
        "\n",
        "#### 2. ML success criteria\n",
        "A list of criteria for a successful outcome to the project in technical terms, for example a certain level of predictive accuracy or a propensity to purchase profile with a given degree of \"lift.\" As with business success criteria, it may be necessary to describe these in subjective terms, in which case the person or persons making the subjective judgment should be identified.\n",
        "\n",
        "> ##### Example:\n",
        "> - The model aims to achieve a recall rate of 95% for identifying customers who are likely to churn.\n",
        "> - The model aims to achieve a precision rate of 90% for identifying high-value customers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1. Business success criteria\n",
        "\n",
        "- Achieve at least a 15% increase in average monthly revenue per listing.\n",
        "- Maintain or increase occupancy rates to at least 75% across listings.\n",
        "- Aim to reduce cancellation rates by at least 10%.\n",
        "\n",
        "\n",
        "\n",
        "#### 2. ML success criteria\n",
        "- Mean Absolute Percentage Error < 0.05\n",
        "- RMSE < 0.1\n",
        "- R-squared values > 0.55\n",
        "- Max error < 0.45\n"
      ],
      "metadata": {
        "id": "Vb2SuZJlKkbn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuRcECj0aQoq"
      },
      "source": [
        "## Data collection\n",
        "\n",
        "### tasks\n",
        "- Specify the data sources\n",
        "- Collect the data\n",
        "- Version control on the data\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. Data collection report\n",
        "A section to describe the data sources and how you want to collect the data.\n",
        "\n",
        "> ##### Example:\n",
        "> - **Data Source:** The origin of the data, such as a database, file, or API. Example: \"The data was collected from the company's customer relationship management (CRM) database.\"\n",
        "> - **Data Type:** The format or structure of the data, such as numerical, categorical, or text. Example: \"The data consists of numerical values representing customer purchase amounts and categorical values representing customer demographics.\"\n",
        "> - **Data Size:** The quantity of data collected. Example: \"The dataset contains 100,000 customer records, with 50 features each.\"\n",
        "> - **Data Collection Method:** The process used to collect the data. Example: \"The data was collected using a web scraping tool that extracted customer information from the company's website.\"\n",
        "\n",
        "\n",
        "#### 2. Data version control report\n",
        "A section to describe data versions, what change happend in the data, how do you backup the data. This should be done after you collect the data.\n",
        "\n",
        "> ##### Example:\n",
        "> - **Data Version:** A unique identifier for each version of the data. Example: \"The current data version is v1.2, which was updated on March 15, 2023.\"\n",
        "> - **Data Change Log:** A record of changes made to the data. Example: \"The data change log shows that the customer demographics feature was updated on February 20, 2023, to include new categories.\"\n",
        "> - **Data Backup:** A copy of the data stored for recovery in case of data loss. Example: \"The company has a daily backup of the data stored on a secure server.\"\n",
        "> - **Data Archiving:** The process of storing and managing historical data. Example: \"The company archives data older than one year to a cloud storage service for long-term retention.\"\n",
        "> - **Data Access Control:** The process of controlling who can access and modify the data. Example: \"The company uses role-based access control to ensure that only authorized personnel can access and modify the data.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Data collection report\n",
        "\n",
        "> - **Data Source:** The dataset used for this analysis was sourced from Kaggle, includes comprehensive data on Airbnb listings. Below is a detailed description of the data collection aspects. The dataset is provided in CSV format, a common and versatile format for tabular data.\n",
        "> - **Data Type:** The data consists of numerical values representing number of accomodates, bedrooms and proces. Categorical values representing type of rooms, beds, proprety types. Datetime values representing date of the first review, date of the last review, date the host started. Text features representing descriptions, names, neigbourhoods.\n",
        "> - **Data Size:** The dataset comprises 74,111 rows and 29 columns.\n",
        "> - **Data Collection Method:** Initial raw dataset\n",
        "downloaded from Kaggle and then cleaned and prepossessed\n",
        "and restored in the same filename.\n",
        "\n",
        "\n",
        "#### 2. Data version control report\n",
        "> - **Data Version:** The current data version is cleaned and prepossessed\n",
        "and restored in the same filename.\n",
        "> - **Data Change Log:** Handled missing values using imputation strategies.\n",
        "> - **Data Backup:** A copy of the data stored for recovery in case of data loss."
      ],
      "metadata": {
        "id": "ssZIkyuvfNzp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1RoNg5PaQoq"
      },
      "source": [
        "## Data quality verification\n",
        "\n",
        "### tasks\n",
        "- Describe data\n",
        "- Define data requirements\n",
        "- Explore the data\n",
        "- Verify the data quality\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. Data description\n",
        "A section to describe the data that has been acquired including its format, its quantity (for example, the number of records and fields in each table), the identities of the fields and any other surface features which have been discovered. Add a table of description of the data features.\n",
        "\n",
        "> ##### Example\n",
        "> - The data acquired for this project includes a dataset of 1000 records with 20 fields each. The fields include customer demographics, purchase history, and product preferences. The data is in a CSV format and is stored in a local database.\n",
        "> - Add a table of description of the data features.\n",
        "\n",
        "#### 2. Data exploration\n",
        "A section to present results of your data exploration, including first findings or initial hypothesis and their impact on the remainder of the project. If appropriate you could include graphs and plots here to indicate data characteristics that suggest further examination of interesting data subsets.\n",
        "\n",
        "> ##### Example\n",
        "> - During data exploration, several interesting patterns and correlations were discovered. For example, there is a strong correlation between the age of customers and their purchase frequency. Additionally, customers who have purchased from the company in the past are more likely to make repeat purchases. These findings suggest that the data is representative of the target audience and that the company's marketing strategies are effective.\n",
        "> - Add charts and figures to present the findings.\n",
        "\n",
        "#### 3. Data requirements\n",
        "A section to describe the data requirements. The requirements can be defined either on the meta-level or directly in the data, and should state the expected conditions of the data, i.e., whether a certain sample is plausible. The requirements can be, e.g., the expected feature values (a range for continuous features or a list for discrete features), the format of the data and the maximum number of missing values. The bounds of the requirements has to be defined carefully to include all possible real world values but discard non-plausible data. Data that does not satisfy the expected conditions could be treated as anomalies and need to be evaluated manually or excluded automatically. To mitigate the risk of anchoring bias in this first phase discussing the requirements with a domain expert is advised. Documentation of the data requirements could be expressed in the form of a schema with strict data types and conditions.\n",
        "\n",
        "> ##### Example\n",
        "> - The data requirements for this project are defined as follows:\n",
        "> > - Customer Demographics: Age should be within the range of 18 to 100 years, and gender should be either male or female.\n",
        "> > - Purchase History: The number of purchases should be greater than or equal to 0, and the total amount spent should be greater than or equal to $0.\n",
        "> > - Product Preferences: The product preferences should be represented as a list of product IDs, and each product ID should be unique and within the range of 1 to 1000.\n",
        "> > - Here we define expectations to satisfy the data requirements.\n",
        "\n",
        "#### 4 Data quality verification report\n",
        "A section to verify and report the quality of the data. Examine the quality of the data, addressing questions such as:\n",
        "- Is the data complete (does it cover all the cases required)?\n",
        "- Is it correct, or does it contain errors and, if there are errors, how common are they?\n",
        "- Are there missing values in the data? If so, how are they represented, where do they occur, and how common are they?\n",
        "\n",
        "> ##### Example\n",
        "> - Completeness: The data is complete in the sense that it covers all the required cases. All customers have demographic information, and all purchases are recorded.\n",
        "> - Correctness: The data appears to be correct, with no obvious errors. However, a manual review of the data is recommended to ensure that there are no errors.\n",
        "> - Missing Values: There are no missing values in the data.\n",
        "> - Overall, the data quality is high, and the data is suitable for analysis and modeling. However, a manual review of the data is recommended to ensure that there are no errors or anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Data description**\n",
        "Here's an overview of the dataset:\n",
        "- Format: CSV\n",
        "- Quantity: 74,111 records and 29 columns\n",
        "- Key Features: Includes numerical, categorical, text, and datetime data types\n",
        "\n",
        "#### **2. Data exploration**\n",
        "\n",
        "Upon initial exploration, we identified several key points:\n",
        "- Numerical Features:\n",
        "Significant presence of missing values in some columns\n",
        "- Categorical Features: Important features include property_type, room_type, bed_type, cancellation_policy, city, among others.\n",
        "Presence of categorical values needing encoding for analysis    \n",
        "- Text Features:Includes free-form text such as description and amenities.\n",
        "Requires preprocessing for meaningful analysis\n",
        "- Datetime Features:\n",
        "Includes dates such as first_review, last_review, and host_since.\n",
        "Requires extraction and transformation for temporal analysis\n",
        "\n",
        "#### **3. Data requirements**\n",
        "- thumbnail_url: No transformation needed (not typically used as a feature, dropped.)\n",
        "- Expected Feature Values: Define ranges for continuous features (e.g., price, number of reviews) or lists for discrete features (e.g., property types, room types).\n",
        "- Data Format: Ensure data formats adhere to specified standards, such as date formats or textual content.\n",
        "    \n",
        "- Maximum Number of Missing Values: Define thresholds for acceptable missing data across features, guiding data cleaning and imputation processes.\n",
        "\n",
        "#### **4. Data quality verification report**\n",
        "The data quality verification process evaluates the integrity and reliability of the dataset through various analyses:\n",
        "- Completeness: Missing data statistics per column were examined, revealing areas requiring imputation or further investigation.\n",
        "- Accuracy:  Quality checks revealed discrepancies that impact data reliability, particularly in numerical and categorical features.\n",
        "    \n",
        "- Missing Values: Strategies like median imputation and default values were used to address missing data systematically.\n",
        "\n",
        "Initial exploration revealed significant missing data across several columns, necessitating robust handling strategies."
      ],
      "metadata": {
        "id": "RKdxu8L1heNA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZCQA0YfF1Yq"
      },
      "source": [
        "## Project feasibility\n",
        "-------------\n",
        "This task involves more detailed fact-finding about all of the resources,constraints, assumptions and other factors that should be considered in determining the data analysis goal and project plan. In the previous task, your objective is to quickly get to the crux of the situation. Here, you want to flesh out the details.\n",
        "\n",
        "### tasks\n",
        "- Assess the project feasibility\n",
        "- Create POC (Proof-of-concept) model\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. inventory of resources\n",
        "\n",
        "List the resources available to the project, including: personnel (business experts, data experts, technical support, machine learning personnel), data (fixed extracts, access to live warehoused or operational data), computing resources (hardware platforms) and software (machine learning tools, other relevant software).\n",
        "\n",
        "#### 2. Requirements, assumptions and constraints\n",
        "\n",
        "List all requirements of the project including schedule of completion, comprehensibility and quality of results and security as well as legal issues.As part of this output, make sure that you are allowed to use the data. List the assumptions made by the project.\n",
        "\n",
        "These may be assumptions about the data that can be checked during machine learning, but may also include non-checkable assumptions about the business upon which the project rests. It is particularly important to list the latter if they form conditions on the validity of the results.\n",
        "\n",
        "List the constraints on the project. These may be constraints on the availability of resources, but may also include technological constraints such as the size of data that it is practical to use for modeling.\n",
        "\n",
        "#### 3. Risks and contingencies\n",
        "\n",
        "List the risks or events that might occur to delay the project or cause it to fail. List the corresponding contingency plans; what action will be taken if the risks happen.\n",
        "\n",
        "\n",
        "#### 4. Costs and benefits\n",
        "\n",
        "Construct a cost-benefit analysis for the project, which compares the costs of the project with the potential benefit to the business if it is successful. The comparison should be as specific as possible.\n",
        "\n",
        "![](https://i.imgur.com/XU2lghc.png)\n",
        "\n",
        "#### 5. Feasibility report\n",
        "\n",
        "Build a POC ML model and explain as a team whether it is feasible to do this ML project or not. If not, then you need to find another business problem. They key factors here are related to data availability, quality, costs and nature of business problem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. inventory of resources\n",
        "\n",
        "- Presonnel: We have  a Data Engineer that is responsible for Data Transformation, Data Analysis and Model Training. We have a Data Scientist that is responsible for Business Understanding, Data Analysis and Model Evaluation. And an ML Engineer that is responsible for Data preparation,Pipelines, CI/CD.\n",
        "- Data: Dataset sourced from Kaggle, which includes 74,111 rows and 29 columns with various features such as numerical, categorical, text, and datetime data.\n",
        "- Computing Resources: Access to cloud computing resources like Google Colab. Most of the times working on local machine.\n",
        "- Machine Learning Tools: Python libraries (e.g., scikit-learn, TensorFlow, Keras), Jupyter notebooks for development and analysis. Data visualization tools (e.g., Matplotlib, Seaborn), data processing libraries (e.g., Pandas, NumPy).\n",
        "\n",
        "#### 2. Requirements, assumptions and constraints\n",
        "\n",
        "- Schedule of Completion: 4-5 weeks for the entire project.\n",
        "- Comprehensibility and Quality of Results: Results should be interpretable and provide actionable insights for pricing optimization.\n",
        "-Usability of Data: Data is clean, relevant, and well-preprocessed for the model.\n",
        "- Data Quality: The data is representative and sufficiently comprehensive for building a reliable model.\n",
        "-Business Context: The factors influencing Airbnb pricing identified in the dataset are consistent with real-world scenarios.\n",
        "-Resource Availability: Limited.\n",
        "- Time Constraints: Limited to 4-5 weeks, requiring efficient project management and prioritization of tasks.\n",
        "-Data Size: The dataset is fixed in size (74,111 rows), so scalability testing might be limited.\n",
        "\n",
        "#### 3. Risks and contingencies\n",
        "\n",
        "- Data Quality Issues: Missing or inaccurate data could lead to poor model performance.\n",
        "- Resource Limitations: Limited access to high-performance computing resources could delay processing and model training.\n",
        "- Model Performance: The model may not achieve the desired accuracy or may overfit/underfit the data.\n",
        "- Team Coordination: Coordination issues among team members could delay the project.\n",
        "\n",
        "Our plan includes this:\n",
        "\n",
        "- Data Quality: Implement robust data preprocessing techniques and validate the data thoroughly before model training.\n",
        "- Resource Limitations: Utilize cloud resources.\n",
        "- Model Performance: Iterate on model tuning, consider alternative algorithms, and perform extensive cross-validation to ensure robustness.\n",
        "- Team Coordination: Regular team meetings and clear task assignments to ensure smooth progress and timely completion.\n",
        "\n",
        "\n",
        "#### 4. Costs and benefits\n",
        "\n",
        "- Time Investment: Significant time commitment from all team members over 4-5 weeks.\n",
        "- Resource Usage: Open cloud and local tools were used.\n",
        "- Software Tools: Open cloud and local tools were used.\n",
        "\n",
        "Let's imagine we're doing real project outside univeristy.\n",
        "Total personnel cost would be 300,000 RUB for our team of 3 people.\n",
        "\n",
        "Using existing hardware, no additional cost. Assunig we pay for the cloud resources 10,000 RUB.\n",
        "\n",
        "Internet and Electricity: 2,000 RUB.\n",
        "Administrative and Documentation: 3,000 RUB.\n",
        "\n",
        "Total Project Cost:\n",
        "- Personnel: 300,000 RUB\n",
        "- Cloud Computing: 10,000 RUB\n",
        "- Internet, electricity, etc: 5,000 RUB\n",
        "\n",
        "Total: 315,000 RUB\n",
        "\n",
        "Benefits\n",
        "1. Skill Development:\n",
        "Enhanced Expertise:\n",
        "Value of acquiring advanced data science and machine learning skills.\n",
        "Estimated value: 50,000 RUB per person.\n",
        "Total Skill Development Value: 150,000 RUB (for 3 team members).\n",
        "2. Project Output:\n",
        "Functional Model can be included in portfolios, enhancing employability.\n",
        "Estimated value: 100,000 RUB.\n",
        "3. Academic Achievement:\n",
        "University Project Completion:\n",
        "Contributing to academic success, potential for awards or recognition.\n",
        "Estimated value: 50,000 RUB.\n",
        "4. Business Insight:\n",
        "\n",
        "Practical Insights for Airbnb Hosts:\n",
        "Potential to improve pricing strategies, increasing rental income.\n",
        "\n",
        "Estimated value: 100,000 RUB (considering potential increase in income over time).\n",
        "\n",
        "Total Project Benefits:\n",
        "-Skill Development: 150,000 RUB\n",
        "-Project Output: 100,000 RUB\n",
        "-Academic Achievement: 50,000 RUB\n",
        "-Business Insight: 100,000 RUB\n",
        "\n",
        "Total: 400,000 RUB\n",
        "\n",
        "\n",
        "This analysis shows that the project is feasible and beneficial, with a significant positive net benefit. The detailed cost and benefit estimation provides a clear understanding of the project's value from both educational and practical perspective\n",
        "\n",
        "![](https://i.imgur.com/XU2lghc.png)\n",
        "\n",
        "#### 5. Feasibility report\n",
        "\n",
        "Model Built POC:\n",
        "\n",
        "Multi-layer Perceptron (MLP) Regressor\n",
        "Configuration: Hidden layers = (100, 50), Max iterations = 500, lr 1e-3\n",
        "\n",
        "Performance:\n",
        "Training MSE: 3.691, Residual Coefficient : 0.528\n",
        "Testing MSE: 3.691, Residual Coefficient : 0.525. The model explains about 53% of the variance in the target variable\n",
        "\n",
        "Model Performance: Moderate. While not ideal, the model is capturing some variance in the data\n",
        "\n",
        "Recommendations:\n",
        "\n",
        "Hyperparameter Tuning: Further adjust parameters for improved performance.\n",
        "Feature Engineering: Enhance features for better model input.\n",
        "Alternative Models: Test other algorithms to compare effectiveness."
      ],
      "metadata": {
        "id": "_p-raqBTuSCd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv9AUIJEaQor"
      },
      "source": [
        "## produce project plan\n",
        "----------------\n",
        "\n",
        "### task\n",
        "\n",
        "Describe the intended plan for achieving the machine learning goals and thereby achieving the business goals. The plan should specify the anticipated set of steps to be performed during the rest of the project including an initial selection of tools and techniques.\n",
        "\n",
        "### output\n",
        "\n",
        "#### 1. Project plan\n",
        "- List the stages to be executed in the project, together with their duration, resources required, inputs, outputs, and dependencies. Where possible, try and make explicit the large-scale iterations in the machine learning process, for example, repetitions of the modeling and evaluation phases. As part of the project plan, it is also important to analyze dependencies between time schedule and risks. Mark results of these analyses explicitly in the project plan, ideally with actions and recommendations if the risks are manifested. Decide at this point which evaluation strategy will be used in the evaluation phase. Your project plan will be a dynamic document. At the end of each phase you’ll review progress and achievements and update the project plan accordingly. Specific review points for these updates should be part of the project plan.\n",
        "\n",
        "- Build a Gantt chart for the project tasks and phases using some online platforms like TeamGantt, jira, goodday, tello, ...etc\n",
        "\n",
        "- Add all of your team members and assign tasks to them preliminary. Then you check daily the progress.\n",
        "\n",
        "#### 2. ML project Canvas\n",
        "At the end of the first phase, you should create a canvas for the project as a summary of this phase.\n",
        "\n",
        "\n",
        "> ##### Example\n",
        "> Follow the link: https://github.com/louisdorard/machine-learning-canvas/blob/master/churn.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the project we divided tasks according to our roles and skills:\n",
        "\n",
        "Andreas: data transformation, data analysis, model training\n",
        "\n",
        "Zukhra: business understanding, data analysis, model evaluation\n",
        "\n",
        "Amir: data preparation, data versioning, application build, CI/CD configuration\n",
        "\n",
        "You can view detailed plan and its completion by this [link](https://docs.google.com/spreadsheets/d/16rn_4RmgNRX4sfpjhVMVTUwoDpTVk2LV-2Xcvrw7c9I/edit?gid=0#gid=0)"
      ],
      "metadata": {
        "id": "BTniiigW5MQ1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}